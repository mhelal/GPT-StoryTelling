{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363752f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print (\"\\n\".join(sys.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "702d755d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': 1, 'structVersion': 2, 'name': 'Microphone Array (Realtek(R) Au', 'hostApi': 0, 'maxInputChannels': 4, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "pa = pyaudio.PyAudio()\n",
    "print(pa.get_default_input_device_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7a2bb2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pptx import Presentation\n",
    "from pptx.util import Cm\n",
    "import speech_recognition as sr\n",
    "import win32com.client as wincom\n",
    "import requests\n",
    "import time\n",
    "import openai\n",
    "# Setup OpenAI API\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import shortuuid\n",
    "\n",
    "# initialize the recognizer\n",
    "r = sr.Recognizer() \n",
    "\n",
    "\n",
    "\n",
    "client = OpenAI(api_key='some key here')# manal.helal os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Youâ€™re a kind helpful art assistant, primary school teacher helping kids prepare for a future assisted by AI. Please be brief in your text responses. No more than 100 words please. Please do not repeat a sentence from one response to the following response. All your coming responses will be collected in a story board at the end and need to be sequential and not redundant. The following prompts you will receive will start with the presentation file name, please keep seperate story line per presentation file names and do not use the presentation filenames in your reponses please. Please be kind to primary school children using you this week.\"}\n",
    "]\n",
    "\n",
    "\n",
    "# Initialize speech synthesis\n",
    "speak = wincom.Dispatch(\"SAPI.SpVoice\")\n",
    "template = 'template.pptx'\n",
    "\n",
    "Prescounter = 1\n",
    "\n",
    "session_ID =  shortuuid.uuid()\n",
    "directory = \"group_\"+str(Prescounter)+\"_\"+session_ID\n",
    "\n",
    "# Create the directory\n",
    "os.makedirs(directory)\n",
    "os.chdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c152d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prescounter = Prescounter + 1\n",
    "\n",
    "session_ID =  shortuuid.uuid()\n",
    "directory = \"group_\"+str(Prescounter)+\"_\"+session_ID\n",
    "\n",
    "# Create the directory\n",
    "os.makedirs(directory)\n",
    "os.chdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb9148c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'group_1_TK5myHQTTP4QQFfvHcqspF'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cda825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if directory exists (in current location)\n",
    "def cdTree(ftp, currentDir):\n",
    "    if currentDir != \"\":\n",
    "        try:\n",
    "            ftp.cwd(currentDir)\n",
    "            return True\n",
    "        #except IOError:\n",
    "        except :\n",
    "            try:\n",
    "                #cdTree(ftp, \"/\".join(currentDir.split(\"/\")[:-1]))\n",
    "                ftp.mkd(currentDir)\n",
    "                ftp.cwd(currentDir)\n",
    "                return True\n",
    "            except:\n",
    "                return False\n",
    "def sendFile (ftp, filename, content):\n",
    "    # write to local file the new content\n",
    "    fhandle = open(filename, \"w\")\n",
    "    fhandle.write(content)\n",
    "    fhandle.close()\n",
    "    # sent to ftp\n",
    "\n",
    "\n",
    "\n",
    "    # local file name you want to upload\n",
    "    #filename = \"some_file.txt\"\n",
    "    with open(filename, \"rb\") as f:\n",
    "        # use FTP's STOR command to upload the file\n",
    "        ftp.storbinary(\"STOR %s\" %filename, f)\n",
    "\n",
    "    # list current files &amp; directories\n",
    "    ftp.dir()\n",
    "\n",
    "def sendImage (ftp, filename):\n",
    "    # local file name you want to upload\n",
    "    #filename = \"some_file.txt\"\n",
    "    with open(filename, \"rb\") as f:\n",
    "        # use FTP's STOR command to upload the file\n",
    "        ftp.storbinary(\"STOR %s\" %filename, f)\n",
    "\n",
    "    # list current files &amp; directories\n",
    "    ftp.dir()\n",
    "def retrieveFile (ftp, filename):\n",
    "    \n",
    "    with open(filename, \"wb\") as f:\n",
    "        # use FTP's RETR command to download the file\n",
    "        ftp.retrbinary(\"RETR %s\" %filename, f.write)\n",
    "    with open(filename) as f:\n",
    "        s = f.read()\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fcc2470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import ftplib\n",
    "session = ftplib.FTP('manalhelal.com','manalorama','Manal1974*')\n",
    "#session.cwd('MANALHELAL.COM/public/files_uh/UKRob')\n",
    "remotepath = 'MANALHELAL.COM/public/files_uh/UKRob'\n",
    "print(cdTree (session, remotepath))\n",
    "session.encoding = \"utf-8\"\n",
    "\n",
    "# create new remote directory in the current remote path\n",
    "print(cdTree (session, directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e1c3bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt (prompt):\n",
    "    # Speech-to-Text\n",
    "    speak.Speak(prompt)\n",
    "\n",
    "    with sr.Microphone() as source:\n",
    "        # read the audio data from the default microphone for 20 seconds\n",
    "        audio_data = r.record(source, duration=20)\n",
    "        print(\"Listening to your Question ..... \")\n",
    "        # convert speech to text\n",
    "        user_input = r.recognize_google(audio_data)\n",
    "        print(f'You: {user_input}')\n",
    "\n",
    "    # or using text input:\n",
    "    #user_input = input(\"User: \")\n",
    "    return user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cca1942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGenText (user_input) :\n",
    "    # Define OpenAI prompt\n",
    "    try:\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        # Generate story content\n",
    "\n",
    "        completion = client.chat.completions.create(model=\"gpt-3.5-turbo\", messages=messages)\n",
    "\n",
    "        response_txt = completion.choices[0].message.content\n",
    "        print(f'ChatGPT: {response_txt}')\n",
    "    except openai.APIResponseValidationError as e:\n",
    "        #Handle API error here, e.g. retry or log\n",
    "        print(f\"OpenAI API returned an  Error: {e}\")\n",
    "        pass\n",
    "        return None\n",
    "    return response_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee70a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGenImage (user_input, ImagesCounter) :\n",
    "    # Generate image\n",
    "    try:\n",
    "        response_image = client.images.generate(prompt=user_input, #open(IMAGE_PATH, \"rb\"),\n",
    "        #mask=open(\"mask.png\", \"rb\"),\n",
    "        #prompt=PROMPT,\n",
    "        model= \"dall-e-3\",\n",
    "        n=1,\n",
    "        style= \"vivid\",\n",
    "        size=\"1024x1024\")\n",
    "\n",
    "        #print(response[\"data\"][0][\"url\"])\n",
    "\n",
    "        image_url = response_image.data[0].url\n",
    "\n",
    "        # Download image\n",
    "        image_response = requests.get(image_url)\n",
    "        image_path = 'image_'+str(ImagesCounter)+'.png'\n",
    "        with open(image_path, 'wb') as f:\n",
    "            f.write(image_response.content)\n",
    "\n",
    "    except :#openai.APIResponseValidationError as e:\n",
    "        #Handle API error here, e.g. retry or log\n",
    "        print(\"OpenAI API returned an  Error:\")\n",
    "        pass\n",
    "        return None, None, None\n",
    "\n",
    "    return image_path, response_image.data[0].revised_prompt, image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f367b387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil, sys \n",
    "def createTitleSlide(template, Prescounter):\n",
    "    # create new presentation\n",
    "    output_pptx = 'children_story_book_'+str(Prescounter+1)+'.pptx'\n",
    "    my_file = Path(output_pptx)\n",
    "    i=1\n",
    "    while my_file.is_file():\n",
    "        output_pptx = 'children_story_book_'+str(Prescounter+1)+'_'+str(i)+'.pptx'\n",
    "        i=i+1\n",
    "        my_file = Path(output_pptx)\n",
    "\n",
    "\n",
    "    shutil.copy(\"../\"+template, output_pptx)\n",
    "    shared_file = 'shared_file_'+output_pptx+'.txt'    \n",
    "\n",
    "    prs = Presentation(output_pptx)\n",
    "    title_slide_layout = prs.slide_layouts[0]\n",
    "    slide = prs.slides.add_slide(title_slide_layout)\n",
    "    title = slide.shapes.title\n",
    "    subtitle = slide.placeholders[1]\n",
    "\n",
    "    title.text = \"AI for Kids\"\n",
    "    subtitle.text = \"UK Robotics Week 2024\"\n",
    "\n",
    "    prs.save(output_pptx)  \n",
    "    return prs, output_pptx, shared_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16385769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createOutlineSlide(prs, output_pptx, about, Contributers):\n",
    "\n",
    "\n",
    "    bullet_slide_layout = prs.slide_layouts[1]\n",
    "\n",
    "    slide = prs.slides.add_slide(bullet_slide_layout)\n",
    "    shapes = slide.shapes\n",
    "\n",
    "    title_shape = shapes.title\n",
    "    body_shape = shapes.placeholders[1]\n",
    "\n",
    "    \n",
    "    # update with parameterised about and contributers names\n",
    "    #about = \"Super Hero who can live in the AI Era using the Generative AI effectively and Ethically\"\n",
    "    title_shape.text = 'This Story is about ' + about\n",
    "\n",
    "    tf = body_shape.text_frame\n",
    "    tf.text = 'This story is created by: '\n",
    "    for i in range(len(Contributers)):\n",
    "        p = tf.add_paragraph()\n",
    "        p.text = str(Contributers[i])\n",
    "        p.level = 1 # 2\n",
    "\n",
    "\n",
    "    prs.save(output_pptx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ce0a9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMediaSlide(prs, output_pptx, response_txt, img_path, response_revised_prompt, slideLayout):\n",
    "    blank_slide_layout = prs.slide_layouts[slideLayout]\n",
    "    slide = prs.slides.add_slide(blank_slide_layout)\n",
    "\n",
    "    left = Cm(0.5)\n",
    "    top = Cm(4.5)\n",
    "    width = height = Cm(14)\n",
    "    pic = slide.shapes.add_picture(img_path, left, top, width=width, height=height)\n",
    "\n",
    "    \n",
    "    tokens = response_txt.split()\n",
    "    splitIndex = int(len(tokens)/2)\n",
    "    first_txt = tokens[0:splitIndex]\n",
    "    second_txt = tokens[splitIndex:]\n",
    "    \n",
    "    # add the text reposne\n",
    "    left = Cm(0.5)\n",
    "    top = Cm(0.5)\n",
    "    height = Cm(4)\n",
    "    width =  Cm(33)\n",
    "    txBox = slide.shapes.add_textbox(left, top, width, height)\n",
    "    tf = txBox.text_frame \n",
    "    tf.word_wrap = True\n",
    "    #add image text to slide        \n",
    "    #tp = tf.add_paragraph()\n",
    "    tf.text = ' '.join(first_txt)\n",
    "\n",
    "\n",
    "    \n",
    "    # add the text reposne\n",
    "    left = Cm(15)\n",
    "    top = Cm(4.5)\n",
    "    height = Cm(5)\n",
    "    width =  Cm(19)\n",
    "    txBox = slide.shapes.add_textbox(left, top, width, height)\n",
    "    tf = txBox.text_frame \n",
    "    tf.word_wrap = True\n",
    "    #add image text to slide        \n",
    "    #tp = tf.add_paragraph()\n",
    "    tf.text = ' '.join(second_txt)\n",
    "    \n",
    "\n",
    "    #create textbox under the image on the same left alignment\n",
    "    top = Cm(10)\n",
    "    txBox = slide.shapes.add_textbox(left, top, width, height)\n",
    "    tf = txBox.text_frame\n",
    "    tf.word_wrap = True\n",
    "    #add image text to slide        \n",
    "    #tp = tf.add_paragraph()\n",
    "    tf.text = response_revised_prompt\n",
    "    \n",
    "    prs.save(output_pptx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f9d3465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def createContentSlide(prompt, prs, output_pptx, ImagesCounter, slideLayout):\n",
    "    user_input = get_prompt(prompt)\n",
    "    s = user_input.lower().strip()\n",
    "    s = re.sub( r'(\\S+) (?:\\1 ?){1,}', r'\\1', s )\n",
    "\n",
    "    if s == \"done\":\n",
    "        return s, None, None, None, None, None\n",
    "    # create a loop until done\n",
    "    speak.Speak(\"Ok, I am working on it, bear with me, please\")\n",
    "    \n",
    "    response_txt = getGenText (output_pptx+\": \" + user_input)   \n",
    "    image_path = None\n",
    "    if not os.path.exists(str(ImagesCounter)):\n",
    "        os.makedirs(str(ImagesCounter))\n",
    "    os.chdir(str(ImagesCounter))\n",
    "    print(cdTree (session, str(ImagesCounter)))\n",
    "    while image_path == None:\n",
    "        image_path, response_revised_prompt, _ = getGenImage(output_pptx+\": \" + user_input, ImagesCounter)\n",
    "        if image_path == None:\n",
    "            speak.Speak(\"This did not work, can you repeat please?\")\n",
    "    \n",
    "    print (\"image_path: \", image_path)\n",
    "    speak.Speak(\"Ok, done\")\n",
    "\n",
    "    sendFile(session, \"genText_\"+str(ImagesCounter)+\".txt\", response_txt)\n",
    "    sendFile(session, \"genImageText_\"+str(ImagesCounter)+\".txt\", response_revised_prompt)\n",
    "    sendImage(session, image_path)   \n",
    "    createMediaSlide (prs, output_pptx, response_txt, image_path, response_revised_prompt, slideLayout)\n",
    "    \n",
    "    os.chdir(\"../\")\n",
    "    print(cdTree (session, \"../\"))\n",
    "\n",
    "    slideLayout=slideLayout+1\n",
    "    if slideLayout > 4:\n",
    "        slideLayout = 1\n",
    "    ImagesCounter=ImagesCounter+1\n",
    "    return s, ImagesCounter, slideLayout, response_txt, image_path, response_revised_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96d2b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFinalSlide(pres, output_pptx):\n",
    "    title_slide_layout = prs.slide_layouts[0]\n",
    "    slide = prs.slides.add_slide(title_slide_layout)\n",
    "    title = slide.shapes.title\n",
    "    subtitle = slide.placeholders[1]\n",
    "\n",
    "    title.text = \"Thank you for your Participation Today\"\n",
    "    subtitle.text = \"We hope you enjoyed this experience and find it useful\"\n",
    "\n",
    "    prs.save(output_pptx)  \n",
    "    return prs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7fb9f3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening to your Question ..... \n",
      "You: Kung Fu Panda and he kicks someone in the face and then he gets arrested hey Google\n",
      "User: cooper\n",
      "User: david\n",
      "User: ely\n",
      "User: tn\n",
      "User: mohammed\n",
      "User: done\n",
      "Listening to your Question ..... \n",
      "You: Kung Fu Panda kicking somebody in the face and getting arrested and he said hey Google\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#prompt = \"Super Hero who can live in the AI Era using the Generative AI effectively and Ethically\"\u001b[39;00m\n\u001b[0;32m     23\u001b[0m VideoGen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m user_input, ImagesCounter, slideLayout, response_txt, image_path, response_revised_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mcreateContentSlide\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCan you explain more what you want in this story.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_pptx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mImagesCounter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslideLayout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m SlidesCounter\u001b[38;5;241m=\u001b[39mSlidesCounter\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Update shared file\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[21], line 13\u001b[0m, in \u001b[0;36mcreateContentSlide\u001b[1;34m(prompt, prs, output_pptx, ImagesCounter, slideLayout)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# create a loop until done\u001b[39;00m\n\u001b[0;32m     11\u001b[0m speak\u001b[38;5;241m.\u001b[39mSpeak(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOk, I am working on it, bear with me, please\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m response_txt \u001b[38;5;241m=\u001b[39m \u001b[43mgetGenText\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_pptx\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m   \n\u001b[0;32m     14\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;28mstr\u001b[39m(ImagesCounter)):\n",
      "Cell \u001b[1;32mIn[16], line 8\u001b[0m, in \u001b[0;36mgetGenText\u001b[1;34m(user_input)\u001b[0m\n\u001b[0;32m      4\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_input})\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Generate story content\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m response_txt \u001b[38;5;241m=\u001b[39m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChatGPT: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse_txt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\manal\\Python8\\lib\\site-packages\\openai\\_utils\\_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\manal\\Python8\\lib\\site-packages\\openai\\resources\\chat\\completions.py:606\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    604\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    605\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\manal\\Python8\\lib\\site-packages\\openai\\_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1228\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1235\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1237\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1238\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1239\u001b[0m     )\n\u001b[1;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mC:\\manal\\Python8\\lib\\site-packages\\openai\\_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\manal\\Python8\\lib\\site-packages\\openai\\_base_client.py:1005\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1004\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mC:\\manal\\Python8\\lib\\site-packages\\openai\\_base_client.py:1053\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1059\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\manal\\Python8\\lib\\site-packages\\openai\\_base_client.py:1005\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1004\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mC:\\manal\\Python8\\lib\\site-packages\\openai\\_base_client.py:1053\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1059\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\manal\\Python8\\lib\\site-packages\\openai\\_base_client.py:1020\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1017\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1019\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1023\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1024\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1027\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1028\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "# Main Loop for each group\n",
    "\n",
    "\n",
    "prs, output_pptx, shared_file = createTitleSlide(template, Prescounter)\n",
    "\n",
    "Prescounter = Prescounter + 1\n",
    "ImagesCounter=SlidesCounter = 0\n",
    "\n",
    "about = get_prompt(\"Please tell me what your story is about\")\n",
    "\n",
    "Contributers=[]\n",
    "contrib=\"\"\n",
    "while contrib != \"done\":\n",
    "    contrib = input(\"User: \")\n",
    "    if contrib.lower() != \"done\":\n",
    "        Contributers.append(contrib)\n",
    "        \n",
    "createOutlineSlide(prs, output_pptx, about, Contributers)\n",
    "SlidesCounter=SlidesCounter+1\n",
    "slideLayout = 1\n",
    "#prompt = \"Super Hero who can live in the AI Era using the Generative AI effectively and Ethically\"\n",
    "\n",
    "VideoGen = False\n",
    "user_input, ImagesCounter, slideLayout, response_txt, image_path, response_revised_prompt = createContentSlide(\"Can you explain more what you want in this story.\", prs, output_pptx, ImagesCounter, slideLayout)\n",
    "SlidesCounter=SlidesCounter+1\n",
    "\n",
    "# Update shared file\n",
    "with open(shared_file, 'w') as f:\n",
    "    f.write(f'{response_txt}\\n{image_path}\\n{response_revised_prompt}\\n')\n",
    "speak.Speak(\" Can you tell me some actions or characteristics you want your superhero to do, or say 'done' if you are finished.\")\n",
    "\n",
    "    \n",
    "while user_input.lower() != \"done\":\n",
    "    #if VideoGen:      \n",
    "    #    VideoGen = False\n",
    "    #    user_input, ImagesCounter, slideLayout, response_txt, image_path, response_revised_prompt = createGenVideoSlide(\" Do you have another action or characteristics, or say 'done' if you are finished.\", prs, output_pptx, ImagesCounter, slideLayout)\n",
    "    #else:\n",
    "    #    VideoGen = True\n",
    "    if SlidesCounter == 2:\n",
    "        user_input, ImagesCounter, slideLayout, response_txt, image_path, response_revised_prompt = createContentSlide(\" Lets start with a new action or characteristics to talk about\", prs, output_pptx, ImagesCounter, slideLayout)\n",
    "    else:\n",
    "        user_input, ImagesCounter, slideLayout, response_txt, image_path, response_revised_prompt = createContentSlide(\" Do you have another action or characteristics, or say 'done' if you are finished.\", prs, output_pptx, ImagesCounter, slideLayout)\n",
    "    if user_input.lower() != \"done\":\n",
    "        SlidesCounter=SlidesCounter+1\n",
    "        # Update shared file\n",
    "        with open(shared_file, 'w') as f:\n",
    "            f.write(f'{response_txt}\\n{image_path}\\n{response_revised_prompt}\\n')\n",
    "\n",
    "\n",
    "speak.Speak(\" Thank you, please check your slides!\")\n",
    "\n",
    "createFinalSlide(prs, output_pptx)\n",
    "# Update shared file\n",
    "with open(shared_file, 'w') as f:\n",
    "    f.write('done\\n')\n",
    "\n",
    "# Play the PowerPoint slide show\n",
    "os.system(f'start {output_pptx}')\n",
    "\n",
    "sendImage(session, output_pptx) \n",
    "os.chdir(\"../\")\n",
    "print(cdTree (session, \"../\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69537b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e06fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d71dea7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cygdrive/c/manal/UKRoboticsWeek/2024/group_1_TK5myHQTTP4QQFfvHcqspF\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bc9261ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "42cf13fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"2024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "34e6b67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path, response_image_revised_prompt, image_url = getGenImage (\"draw an image for me about learning Pepper Robot using Generative AI\", 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1dc8d529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://oaidalleapiprodscus.blob.core.windows.net/private/org-xJYRl7aFvxKqyTpAY0qA4fDM/user-QBBpqol6ioymZdq7dRphXtjx/img-1we07QcDZ8iqZpYnwqQ3S6Zd.png?st=2024-06-17T20%3A33%3A54Z&se=2024-06-17T22%3A33%3A54Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-06-17T17%3A12%3A11Z&ske=2024-06-18T17%3A12%3A11Z&sks=b&skv=2023-11-03&sig=ZqcvGeSDCzyIpX7W69EGvc1qG6VvWJ6z5qGZtDxuIoc%3D'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "48a18ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--   1 manalorama pg1675152 10678031 Jun 17 14:31 children_story_book_4.pptx\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "speak.Speak(\" Thank you, please check your slides!\")\n",
    "\n",
    "createFinalSlide(prs, output_pptx)\n",
    "# Update shared file\n",
    "with open(shared_file, 'w') as f:\n",
    "    f.write('done\\n')\n",
    "\n",
    "# Play the PowerPoint slide show\n",
    "os.system(f'start {output_pptx}')\n",
    "\n",
    "sendImage(session, output_pptx) \n",
    "os.chdir(\"../\")\n",
    "print(cdTree (session, \"../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2f30d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
